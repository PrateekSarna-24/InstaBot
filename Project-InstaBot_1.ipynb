{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a57bc96",
   "metadata": {},
   "source": [
    "## Project: InstaBot - I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb46ed",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65248e",
   "metadata": {},
   "source": [
    "Your friend has opened a new Food Blogging handle on Instagram and wants to get famous. \n",
    "\n",
    "He wants to follow a lot of people so that he can get noticed quickly but it is a tedious task so he asks you to help him.\n",
    "\n",
    "As you have just learned automation using Selenium, you decided to help him by creating an Instagram Bot.\n",
    "\n",
    "You need to create different functions for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4b12c",
   "metadata": {},
   "source": [
    "### Project Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703ddab",
   "metadata": {},
   "source": [
    "1. Login to your Instagram Handle\n",
    "\n",
    "    1.1 Submit with sample username and password\n",
    "\n",
    "\n",
    "2. Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”\n",
    "\n",
    "    2.1 Note : Make sure to avoid printing hashtags\n",
    "\n",
    "\n",
    "3. Searching and Opening a profile using \n",
    "\n",
    "    3.1 Open profile of “So Delhi” \n",
    "\n",
    "\n",
    "4. Follow/Unfollow given handle - \n",
    "\n",
    "    4.1 Open the Instagram Handle of “So Delhi”\n",
    "\n",
    "    4.2 Start following it. Print a message if you are already following\n",
    "\n",
    "    4.3 After following, unfollow the instagram handle. Print a message if you have already unfollowed.\n",
    "\n",
    "\n",
    "5. Like/Unlike posts\n",
    "\n",
    "    5.1 Liking the top 30 posts of the ‘dilsefoodie'. Print message if you have already liked it.\n",
    "\n",
    "    5.2 Unliking the top 30 posts of the ‘dilsefoodie’. Print message if you have already unliked it.\n",
    "\n",
    "\n",
    "6. Extract list of followers\n",
    "\n",
    "    6.1 Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’.\n",
    "\n",
    "    6.2 Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you.\n",
    "\n",
    "\n",
    "7. Check the story of ‘coding.ninjas’. Consider the following Scenarios and print error messages accordingly -\n",
    "\n",
    "    7.1 If You have already seen the story.\n",
    "\n",
    "    7.2 Or The user has no story.\n",
    "\n",
    "    7.3 Or View the story if not yet seen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f67f6",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a1def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68435bd8",
   "metadata": {},
   "source": [
    "### About WebDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de257cd",
   "metadata": {},
   "source": [
    "WebDriver drives a browser natively, as a user would, either locally or on a remote machine using the Selenium server, marks a leap forward in terms of browser automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa8fc1",
   "metadata": {},
   "source": [
    "### Creating a Driver Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb989ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebService = Service(executable_path = 'D:\\chromedriver_win32\\chromedriver')\n",
    "driver = webdriver.Chrome(service = WebService)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1371e0",
   "metadata": {},
   "source": [
    "### Problem 1: Loging In"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd424b",
   "metadata": {},
   "source": [
    "#### Opening Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "748750d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_in(username, password) :\n",
    "    instagram_link = 'https://www.instagram.com/'\n",
    "    driver.get(instagram_link)\n",
    "    ## waiting explicitly till the input elements load in the page\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    input_elements = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'input')))\n",
    "    username_input = input_elements[0]\n",
    "    password_input = input_elements[1]\n",
    "    ## passing arguments\n",
    "    username_input.send_keys(username)\n",
    "    password_input.send_keys(password)\n",
    "    ## log in button has an attribute \"type = submit\" so just calling the submit method on password element\n",
    "    password_input.submit()\n",
    "    try :\n",
    "        ## waiting till \"notification\" appears on the screen\n",
    "        not_now_btn = wait.until(EC.presence_of_all_elements_located((By.XPATH, '//button[contains(@class, \"_a9_1\")]')))\n",
    "        not_now_btn.click()\n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21eb3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'ashmit3961'\n",
    "password = 'ay@130308'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "919aaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_in(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91595d1",
   "metadata": {},
   "source": [
    "### Problem 2: Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ba6d3",
   "metadata": {},
   "source": [
    "#### Defining Function to return List of Profile Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54b56552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_get_all_handles(topic) :\n",
    "    ## going to main page\n",
    "    instagram_link = 'https://www.instagram.com/'\n",
    "    driver.get(instagram_link)\n",
    "    ## finding search box\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    search_btn = wait.until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, 'Search')))\n",
    "    search_btn.click()\n",
    "    search_box = driver.find_element(By.TAG_NAME, 'input')\n",
    "    time.sleep(1)\n",
    "    ## sending text to search box\n",
    "    search_box.send_keys(topic)\n",
    "    time.sleep(3)\n",
    "    ## waiting explicitly till search result list appears\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    search_result_list = wait.until(EC.presence_of_element_located((By.XPATH, '//div[starts-with(@class, \"x9f619 x78zum5 xdt5ytf x12dtdjy x6ikm8r x1odjw0f x4uap5 x18d9i69 xkhd6sd xh8yej3 x1iyjqo2 xocp1fn\")]')))\n",
    "    time.sleep(3)\n",
    "    ## Parsing the element HTML to get profile link list\n",
    "    search_result_list_html_object = BeautifulSoup(search_result_list.get_attribute('outerHTML'), 'html.parser')\n",
    "    all_profile_links = search_result_list_html_object.find_all('a')\n",
    "    ##### Calling the function to change the links to names\n",
    "    names = get_names_from_links(all_profile_links)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32346d8d",
   "metadata": {},
   "source": [
    "#### Extracting Names out of Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eb82938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_from_links(profile_link_list) :\n",
    "    for i in range(len(profile_link_list)) :\n",
    "        profile = profile_link_list[i]\n",
    "        ## this span element contains name\n",
    "        span_element = profile.find(class_ = 'x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs xt0psk2 x1i0vuye xvs91rp x1s688f x5n08af x10wh9bi x1wdrske x8viiok x18hxmgj')\n",
    "        profile_link_list[i] = span_element\n",
    "        ## if no span element then returning None\n",
    "        if span_element :\n",
    "            profile_link_list[i] = span_element.get_text()\n",
    "    return profile_link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956803b8",
   "metadata": {},
   "source": [
    "#### Runnnig The query on \"food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c0fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = search_and_get_all_handles('food')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fab746",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53c6ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food__junction\n",
      "foodtalkindia\n",
      "dilsefoodie\n",
      "foodwithbackbanchers\n",
      "swissfoodstagram\n",
      "caarafood\n",
      "food\n",
      "bbuzzz08\n",
      "hollybelly_foodboutique\n",
      "meghnasfoodmagic\n",
      "foodsandflavorsbyshilpi\n",
      "the.food.cravers\n",
      "yourfoodlab\n",
      "delhi_food_shaukeen\n",
      "tasty.foodrecipes\n",
      "foodfitnessnfun\n",
      "funfoodandfrolic\n",
      "funnfoodpark\n",
      "delhifoodnest\n",
      "foodiesafarii\n",
      "delhifoodwalks\n",
      "littlefoodco\n",
      "foodiechina888\n",
      "foodiebyheart2.0\n",
      "saltinall\n",
      "eatlikeamaniac\n",
      "delhites_food_blogger\n",
      "shecooks.healthy\n",
      "foodthatmeltshearts\n",
      "foodie_bahu\n",
      "myfoodproject\n",
      "foodcrazer\n",
      "food_is_lobe\n",
      "foodnetwork\n",
      "food.o.holic\n",
      "food_india_lover\n",
      "theclassyfoodophile\n",
      "foodblowen\n",
      "bongeats\n",
      "silly_food_tales\n",
      "chamber_of_food\n",
      "foodtrippers_by_manral\n",
      "foodcraver109\n",
      "liveforfood007\n",
      "food.darzee\n",
      "foodiesince96\n",
      "thisisdelhi\n",
      "foodshood_delhi\n"
     ]
    }
   ],
   "source": [
    "for name in names :\n",
    "    if name :\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d07307",
   "metadata": {},
   "source": [
    "### Problem 3: Searching & Opening Profile of 'So Delhi'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fab1f8",
   "metadata": {},
   "source": [
    "#### Defining Function to search and open an Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0446a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_open_a_profile(profile_name) :\n",
    "    ## returning to main page\n",
    "    instagram_link = 'https://www.instagram.com/'\n",
    "    driver.get(instagram_link)\n",
    "    time.sleep(2)1\n",
    "    ## waiting explicitly till the search_box appears\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    search_btn = wait.until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, 'Search')))\n",
    "    search_btn.click()\n",
    "    time.sleep(1)\n",
    "    search_box = driver.find_element(By.TAG_NAME, 'input')\n",
    "    time.sleep(1)\n",
    "    ## sending text to search box\n",
    "    search_box.send_keys(profile_name)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    ## Getting the element which contains the link of first search result\n",
    "    search_result_list = driver.find_element(By.XPATH, '//div[starts-with(@class, \"x9f619 x78zum5 xdt5ytf x12dtdjy x6ikm8r x1odjw0f x4uap5 x18d9i69 xkhd6sd xh8yej3 x1iyjqo2 xocp1fn\")]')\n",
    "    search_result_list_html = BeautifulSoup(search_result_list.get_attribute('outerHTML'), 'html.parser')\n",
    "    profile_link = search_result_list_html.find('a')\n",
    "    ## extracting url of profile link\n",
    "    profile_link = profile_link.get('href')\n",
    "    time.sleep(2)\n",
    "    profile_link = 'https://www.instagram.com' + profile_link\n",
    "    driver.get(profile_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995573f",
   "metadata": {},
   "source": [
    "#### Calling Function to open \"sodelhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7712d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_and_open_a_profile('sodelhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7421b",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dbecaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.instagram.com/sodelhi/\n"
     ]
    }
   ],
   "source": [
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396b00a",
   "metadata": {},
   "source": [
    "### Problem 4: Follow/Unfollow \"So Delhi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a725e7",
   "metadata": {},
   "source": [
    "#### Defining Function to Follow an Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82d8f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def follow_profile(profile_name) :\n",
    "    try :\n",
    "        ## trying opening the profile first with already created function above\n",
    "        search_and_open_a_profile(profile_name)\n",
    "    except :\n",
    "        print(\"Couldn't Open the Profile\")\n",
    "    try :\n",
    "        ## waiting explicitly till follow button appears\n",
    "        wait = WebDriverWait(driver, 2) \n",
    "        follow_button = wait.until(EC.presence_of_element_located((By.XPATH, \"//button[starts-with(@class, '_acan _acap _acas _aj1-')]\")))\n",
    "        button_text = driver.find_element(By.XPATH, \"//button[starts-with(@class, '_acan _acap _acas _aj1-')]/div/div\").text\n",
    "        if button_text == 'Follow' :\n",
    "            follow_button.click()\n",
    "            print('Now Follwing !!!')\n",
    "    except :\n",
    "        print('Already Following !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13027c2b",
   "metadata": {},
   "source": [
    "#### Defining Function to Unfollow an account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d027cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfollow_profile(profile_name) :\n",
    "    try :\n",
    "        ## trying opening the profile first with already created function above\n",
    "        search_and_open_a_profile(profile_name)\n",
    "    except :\n",
    "        print(\"Couldn't Open the Profile\")\n",
    "    try :\n",
    "        ## waiting explicitly till follow button appears\n",
    "        wait = WebDriverWait(driver, 2)\n",
    "        unfollow_button = wait.until(EC.presence_of_element_located((By.XPATH, \"//button[starts-with(@class, '_acan _acap _acat _aj1-')]\")))\n",
    "        button_text = driver.find_element(By.XPATH, \"//button[starts-with(@class, '_acan _acap _acat _aj1-')]/div/div\").text\n",
    "        if button_text == 'Following' :\n",
    "            print('Unfollowing Now !!!')\n",
    "            unfollow_button.click()\n",
    "            ## here after clicking \"unfollow\" a drop down element was opened in which \"actual\" unfollow button is at LAST\n",
    "            unfollow_button_options = driver.find_elements(By.XPATH, \"//div[starts-with(@class, 'x1i10hfl x1qjc9v5 xjbqb8w xjqpnuy xa49m3k xqeqjp1 x2hbi6w x13fuv20 xu3j5b3 x1q0q8m5 x26u7qi x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xdl72j9 x2lah0s xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r x2lwn1j xeuugli xexx8yu x4uap5 x18d9i69 xkhd6sd x1n2onr6 x16tdsg8 x1hl2dhg xggy1nq x1ja2u2z x1t137rt x1q0g3np x87ps6o x1lku1pv x1a2a7pz x1dm5mii x16mil14 xiojian x1yutycm x1lliihq x193iq5w xh8yej3')]\")\n",
    "            ## 'Actual' unfollow button is at last of list\n",
    "            unfollow_button_options[-1].click()\n",
    "    except :\n",
    "        print('Already Not Following !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15092fd",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b6956",
   "metadata": {},
   "source": [
    "#### Making \"follow\" request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e22ef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Follwing !!!\n"
     ]
    }
   ],
   "source": [
    "follow_profile('sodelhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535886c",
   "metadata": {},
   "source": [
    "#### Checking Status of follow request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd34989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Follwing !!!\n"
     ]
    }
   ],
   "source": [
    "follow_profile('sodelhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e615667",
   "metadata": {},
   "source": [
    "#### Making \"Unfollw\" request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41347ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfollowing Now !!!\n"
     ]
    }
   ],
   "source": [
    "unfollow_profile('sodelhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ac976",
   "metadata": {},
   "source": [
    "#### Checking status of unfollow request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4563a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Not Following !!!\n"
     ]
    }
   ],
   "source": [
    "unfollow_profile('sodelhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a26ea",
   "metadata": {},
   "source": [
    "### Problem 5: Like/Unlike Top 30 posts of \"dilsefoodie\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de888c53",
   "metadata": {},
   "source": [
    "#### Explanation : The code has been divided into 3 functions - \n",
    "1. First is get_posts_link() which returns the links of posts from an account\n",
    "2. like_posts() which traverse each post and likes it, if already liked then it returns the message - \"already liked\"\n",
    "3. unlike_posts() which traverse each post and unlikes it, if already liked then it returns the message - \"already unliked\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f919a11",
   "metadata": {},
   "source": [
    "#### First getting the links of all posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0736bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_link(profile_name) :\n",
    "    try :\n",
    "        search_and_open_a_profile(profile_name)\n",
    "    except :\n",
    "        print(\"Couldn't Open the Profile\")\n",
    "    time.sleep(2)\n",
    "    ## height of scrollbar\n",
    "    current_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "    time.sleep(2)\n",
    "    ## scrolling through the list till we get atleast 30 or all posts\n",
    "    ## since the content is dynamic we need to scroll to get full results\n",
    "    while True :\n",
    "        driver.execute_script('window.scrollTo(0, arguments[0])', current_height)\n",
    "        time.sleep(1)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "        posts = driver.find_elements(By.XPATH, '//article/div/div//a')\n",
    "        if len(posts) > 30 :\n",
    "            break\n",
    "        if current_height == new_height :\n",
    "            break\n",
    "        current_height = new_height\n",
    "    if len(posts) >= 30 :\n",
    "        posts = posts[0 : 30]\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf26d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = get_posts_link('dilsefoodie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e82f1a",
   "metadata": {},
   "source": [
    "#### From elements extracting their links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "295629f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(posts)) :\n",
    "    posts[i] = (posts[i].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a12b0",
   "metadata": {},
   "source": [
    "#### 5.1 Liking Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e502aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def like_posts(posts) :\n",
    "    i = 1\n",
    "    for post in posts :\n",
    "        driver.get(post)\n",
    "        time.sleep(1.5)\n",
    "        driver.execute_script('window.scrollBy(0, 1100)')\n",
    "        time.sleep(1)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        ## finding the like button\n",
    "        like_element = wait.until(EC.presence_of_element_located((By.XPATH, \"//section[starts-with(@class, '_aamu _ae3_')]//span/div/div/span\")))\n",
    "        html_obj = BeautifulSoup(like_element.get_attribute('innerHTML'), 'html.parser')\n",
    "        like_status = html_obj.title.string\n",
    "        like_button = driver.find_element(By.XPATH, \"//div[@class = '_ae2s']/section[starts-with(@class, '_aamu _ae3_')]/span/div\")\n",
    "        if like_status == 'Unlike' :\n",
    "            ending = None\n",
    "            if i == 1 or i == 21:\n",
    "                ending = 'st'\n",
    "            elif i == 2 or i == 22:\n",
    "                ending = 'nd'\n",
    "            elif i == 3 or i == 23:\n",
    "                ending = 'rd'\n",
    "            else :\n",
    "                ending = 'th'\n",
    "            print(str(i) + ending,\"Post has already been liked\")\n",
    "        else :\n",
    "            like_button.click()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c866d38e",
   "metadata": {},
   "source": [
    "#### calling the Function to like the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a81b7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_posts(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e38be",
   "metadata": {},
   "source": [
    "#### Calling the function again to check the result if the posts were liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cacf54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Post has already been liked\n",
      "2nd Post has already been liked\n",
      "3rd Post has already been liked\n",
      "4th Post has already been liked\n",
      "5th Post has already been liked\n",
      "6th Post has already been liked\n",
      "7th Post has already been liked\n",
      "8th Post has already been liked\n",
      "9th Post has already been liked\n",
      "10th Post has already been liked\n",
      "11th Post has already been liked\n",
      "12th Post has already been liked\n",
      "13th Post has already been liked\n",
      "14th Post has already been liked\n",
      "15th Post has already been liked\n",
      "16th Post has already been liked\n",
      "17th Post has already been liked\n",
      "18th Post has already been liked\n",
      "19th Post has already been liked\n",
      "20th Post has already been liked\n",
      "21st Post has already been liked\n",
      "22nd Post has already been liked\n",
      "23rd Post has already been liked\n",
      "24th Post has already been liked\n",
      "25th Post has already been liked\n",
      "26th Post has already been liked\n",
      "27th Post has already been liked\n",
      "28th Post has already been liked\n",
      "29th Post has already been liked\n",
      "30th Post has already been liked\n"
     ]
    }
   ],
   "source": [
    "like_posts(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe3ec0",
   "metadata": {},
   "source": [
    "#### 5.2 Unliking Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "114af178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlike_posts(posts) :\n",
    "    i = 1\n",
    "    for post in posts :\n",
    "        driver.get(post)\n",
    "        time.sleep(1.5)\n",
    "        driver.execute_script('window.scrollBy(0, 1100)')\n",
    "        time.sleep(1)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        like_element = wait.until(EC.presence_of_element_located((By.XPATH, \"//section[starts-with(@class, '_aamu _ae3_')]//span/div/div/span\")))\n",
    "        html_obj = BeautifulSoup(like_element.get_attribute('innerHTML'), 'html.parser')\n",
    "        like_status = html_obj.title.string\n",
    "        like_button = driver.find_element(By.XPATH, \"//div[@class = '_ae2s']/section[starts-with(@class, '_aamu _ae3_')]/span/div\")\n",
    "        if like_status == 'Like' :\n",
    "            ending = None\n",
    "            if i == 1 or i == 21:\n",
    "                ending = 'st'\n",
    "            elif i == 2 or i == 22:\n",
    "                ending = 'nd'\n",
    "            elif i == 3 or i == 23:\n",
    "                ending = 'rd'\n",
    "            else :\n",
    "                ending = 'th'\n",
    "            print(str(i) + ending,\"Post has already been Unliked\")\n",
    "        else :\n",
    "            like_button.click()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7de75a",
   "metadata": {},
   "source": [
    "#### Calling the Function to unlike all the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8651d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlike_posts(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97887bc4",
   "metadata": {},
   "source": [
    "#### Calling Again to check if the posts has been unliked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48dab847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Post has already been Unliked\n",
      "2nd Post has already been Unliked\n",
      "3rd Post has already been Unliked\n",
      "4th Post has already been Unliked\n",
      "5th Post has already been Unliked\n",
      "6th Post has already been Unliked\n",
      "7th Post has already been Unliked\n",
      "8th Post has already been Unliked\n",
      "9th Post has already been Unliked\n",
      "10th Post has already been Unliked\n",
      "11th Post has already been Unliked\n",
      "12th Post has already been Unliked\n",
      "13th Post has already been Unliked\n",
      "14th Post has already been Unliked\n",
      "15th Post has already been Unliked\n",
      "16th Post has already been Unliked\n",
      "17th Post has already been Unliked\n",
      "18th Post has already been Unliked\n",
      "19th Post has already been Unliked\n",
      "20th Post has already been Unliked\n",
      "21st Post has already been Unliked\n",
      "22nd Post has already been Unliked\n",
      "23rd Post has already been Unliked\n",
      "24th Post has already been Unliked\n",
      "25th Post has already been Unliked\n",
      "26th Post has already been Unliked\n",
      "27th Post has already been Unliked\n",
      "28th Post has already been Unliked\n",
      "29th Post has already been Unliked\n",
      "30th Post has already been Unliked\n"
     ]
    }
   ],
   "source": [
    "unlike_posts(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1f947",
   "metadata": {},
   "source": [
    "### Problem 6: Extract list of first 500 followers of :\n",
    "1. foodtalkindia \n",
    "2. sodelhi.\n",
    "**Also, Get the names of common followers of 'foodtalkindia' that you follow but they dont follow you back**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822af5c2",
   "metadata": {},
   "source": [
    "#### Expanation: The problem has been divided into 2 functions :\n",
    "1. get_followers() which returns the profile links\n",
    "2. get_usernames() which extracts the name out of profile links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5ec49",
   "metadata": {},
   "source": [
    "#### Getting Profile Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c52aec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_followers(profile_name) :\n",
    "    try :\n",
    "        search_and_open_a_profile(profile_name)\n",
    "    except :\n",
    "        print(\"Couldn't Open the Profile\")\n",
    "    try :\n",
    "        time.sleep(1)\n",
    "        wait = WebDriverWait(driver, 10) \n",
    "        followers = wait.until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, 'followers')))\n",
    "        followers.click()\n",
    "        followers_list_container = wait.until(EC.presence_of_element_located((By.XPATH, \"//div[starts-with(@class, 'x7r02ix xf1ldfh x131esax xdajt7p xxfnqb6 xb88tzc xw2csxc x1odjw0f x5fp0pe')]//div[starts-with(@class, '_aano')]\")))\n",
    "        current_height = driver.execute_script(\"return document.querySelector('._aano').scrollHeight;\")\n",
    "        time.sleep(2)\n",
    "        ## scrolling till the page has atleast 1000 followers or all followers\n",
    "        while True :\n",
    "            driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', followers_list_container)\n",
    "            time.sleep(1)\n",
    "            new_height = driver.execute_script(\"return document.querySelector('._aano').scrollHeight;\")\n",
    "            followers_list = driver.find_elements(By.XPATH, \"//div[starts-with(@class, 'x7r02ix xf1ldfh x131esax xdajt7p xxfnqb6 xb88tzc xw2csxc x1odjw0f x5fp0pe')]//div[starts-with(@class, '_aano')]//a\")\n",
    "            if len(followers_list) >= 1000 :\n",
    "                break\n",
    "            if current_height == new_height :\n",
    "                break\n",
    "            current_height = new_height\n",
    "        if not (len(followers_list) >= 500) :\n",
    "            print('This Account has restricted the view of all followers !!!\\nBut here are some of them : ')\n",
    "        get_usernames(followers_list)\n",
    "        followers_list = list(set(followers_list))\n",
    "        if len(followers_list) >= 500 :\n",
    "            followers_list = followers_list[0 : 500]\n",
    "        for i in range(len(followers_list)) :\n",
    "            print(str(i + 1)+'.',followers_list[i])\n",
    "    except :\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f18d8",
   "metadata": {},
   "source": [
    "#### Extracting Names out of Profile Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d4a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usernames(followers_list) :\n",
    "    for i in range(len(followers_list)) :\n",
    "        ## The name is present in the 2nd last position in the string after spliting from \"/\"\n",
    "        name = followers_list[i].get_attribute('href').split('/')[-2]\n",
    "        followers_list[i] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2001512",
   "metadata": {},
   "source": [
    "#### 6.1 Calling For 'SoDelhi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d2ac1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. aarushi8251\n",
      "2. gbav142019\n",
      "3. vir_malik2000\n",
      "4. sanchitaggarwal\n",
      "5. _faiez_sheikh_\n",
      "6. varshaagrawal_1705\n",
      "7. its_ridhima_8\n",
      "8. romit_rg\n",
      "9. shwetakansal_29\n",
      "10. zsl3511\n",
      "11. __bhagyesh___\n",
      "12. drx.azmi\n",
      "13. naman_mittal_10\n",
      "14. hazel_dentist\n",
      "15. adityaingole_\n",
      "16. mandhirsingh2\n",
      "17. pehal_dua8\n",
      "18. aayat_ansari_62\n",
      "19. thedisciplined_pandit\n",
      "20. ashmigautam001\n",
      "21. sourabh_kagra_\n",
      "22. sachiiii_23\n",
      "23. ar.y2023\n",
      "24. monyca_x\n",
      "25. lost_traveller.14\n",
      "26. kahaf.haleema\n",
      "27. tina.vasudev\n",
      "28. gurmeetkaur1980\n",
      "29. kukussw\n",
      "30. withluv.anu\n",
      "31. simps4vaanu\n",
      "32. k_ray_zyy\n",
      "33. priyanka_dwivedi_07\n",
      "34. makkar464\n",
      "35. jigisha_basu\n",
      "36. _damak.__\n",
      "37. tripathiooo3\n",
      "38. naveenmheswari\n",
      "39. tums12345\n",
      "40. anji_singh1993\n",
      "41. annsandragodly\n",
      "42. home_for_you000\n",
      "43. akshit_garg97\n",
      "44. delhiclicks0508\n",
      "45. manya_singh3\n",
      "46. __ashishp___\n",
      "47. ditysingh1222\n",
      "48. misbah._.qazi\n",
      "49. its_amit_4uh\n",
      "50. shubham_saini03\n",
      "51. a.k.singh_4all\n",
      "52. deepanshu.maheshwarii\n",
      "53. nishantpayal027\n",
      "54. thearyantripathi\n",
      "55. ankitjha_in_\n",
      "56. _sionara__\n",
      "57. aditi_badola02\n",
      "58. noorshergill.mua\n",
      "59. ritesh.r_o\n",
      "60. delhi___ki_galiya\n",
      "61. javedali574\n",
      "62. iamnoor_17\n",
      "63. bhavyaejain\n",
      "64. sayhitomoli\n",
      "65. namita8275\n",
      "66. shivsinghb8\n",
      "67. ishagoel65\n",
      "68. akash.d.majestic\n",
      "69. krrish_132\n",
      "70. _jayrajkaundilya_\n",
      "71. jyotigulia5626\n",
      "72. amberinasud\n",
      "73. prachi_lembhe19\n",
      "74. thisishimanshubhatt\n",
      "75. vijhriday\n",
      "76. manisha.agarwal1212\n",
      "77. lordisbored\n",
      "78. quillsphere\n",
      "79. imashwanirajput\n",
      "80. shivammkumarrr\n",
      "81. himavijay6\n",
      "82. sa4742575\n",
      "83. _.rishikesh_._\n",
      "84. itsbusiness215\n",
      "85. neha14sharma\n",
      "86. vaibhavgaur_artist\n",
      "87. raj_mehta63\n",
      "88. walia_nance\n",
      "89. antic_lad\n",
      "90. iajeetsinghh\n",
      "91. piasharma_38\n",
      "92. rachitkapur2\n",
      "93. scorpion071991\n",
      "94. pihuverma9092021\n",
      "95. rick01930220\n",
      "96. _raghav_sharma_7\n",
      "97. khushwant.singh9\n",
      "98. d1vya_chauhan\n",
      "99. sarangdharkumarsinha\n",
      "100. _faiqua\n",
      "101. sakshi_811\n",
      "102. priyankamahalwal\n",
      "103. shashitomar04_\n",
      "104. krishnaabhaati\n",
      "105. ilobbpancakes\n",
      "106. mallikaaa.c\n",
      "107. skonelife\n",
      "108. bhardwaj_1001\n",
      "109. 2784.jiya\n",
      "110. dograsunnyy\n",
      "111. prabhjeetkaur1883\n",
      "112. priyanshu2552_\n",
      "113. tanyayayax\n",
      "114. harshitarawat01\n",
      "115. rajni.bajaj65\n",
      "116. foodforkers\n",
      "117. manjarir\n",
      "118. _simraaa_\n",
      "119. gurmeetkaur.gk84.gk\n",
      "120. kaif.qureshi092\n",
      "121. missaafi__\n",
      "122. snehak2303\n",
      "123. kabir121a\n",
      "124. neelanshi21\n",
      "125. its_lukman_sheikh_\n",
      "126. 03manna07\n",
      "127. shreshtha_rashmi_singhal\n",
      "128. priyanka.goel.22\n",
      "129. the__mahima\n",
      "130. official_yadav_nee2\n",
      "131. _vaibs18_\n",
      "132. jan_nnat5454\n",
      "133. lil_k_ashvi\n",
      "134. vanshika_vermaa13\n",
      "135. anshulsinghroha\n",
      "136. k4rtikgupta\n",
      "137. selenophile___05_\n",
      "138. parnamika_s\n",
      "139. realpoddar\n",
      "140. khurana9560\n",
      "141. itsmadbatter\n",
      "142. aviotik\n",
      "143. _ishimalik\n",
      "144. mohitmalik8506\n",
      "145. cutybawa\n",
      "146. himanshiy1\n",
      "147. nidhi.kaizen\n",
      "148. shivyapvt\n",
      "149. bhawna_singh005\n",
      "150. gourav1903\n",
      "151. turquoisezinnia\n",
      "152. oyekamaloye\n",
      "153. niharikadahiya_14\n",
      "154. shetal.agarwal\n",
      "155. d._akriti\n",
      "156. vidhish29\n",
      "157. mamta.ashi\n",
      "158. avneetkaur.n\n",
      "159. gayatri.singh.14203544\n",
      "160. dimplevarma7\n",
      "161. gifts_galore_official\n",
      "162. kaminisetia\n",
      "163. palakb__01\n",
      "164. aboutxalisha\n",
      "165. mk_kalsi__\n",
      "166. unrecognizedhuman\n",
      "167. _indrita_chandra_\n",
      "168. meenu.dhingra.376\n",
      "169. interio_idea\n",
      "170. yamekaur\n",
      "171. riyavashisth__\n",
      "172. sauravsharma.98\n",
      "173. navyaa_kaur_9799\n",
      "174. __yash__rao\n",
      "175. nikisfun\n",
      "176. yuktiiverma\n",
      "177. kavita_si77\n",
      "178. ishan1008\n",
      "179. vasumehtaofficial\n",
      "180. its.simm22\n",
      "181. pra.bhat_pathak\n",
      "182. mrs_aarti_kakkar\n",
      "183. iamsanjeevkumar\n",
      "184. rrahulsarin\n",
      "185. adhuri_khaani_2020\n",
      "186. p.vttt_\n",
      "187. shashwat.dawar\n",
      "188. gaurav_09k\n",
      "189. shaktifashion2\n",
      "190. mamta.chawla23\n",
      "191. csambikanayyar\n",
      "192. preeti_dogra79\n",
      "193. meenu.narang05\n",
      "194. aryan.mj1\n",
      "195. preetibatra07\n",
      "196. gaurav.verma.k\n",
      "197. saheli6217\n",
      "198. i_am_ir_fan_khan\n",
      "199. _prernachauhan\n",
      "200. 5odhii\n",
      "201. priyanka_n_arora\n",
      "202. bhand.sal\n",
      "203. tanvi.pvtx\n",
      "204. ansarirahma\n",
      "205. 111shubhamsingh111\n",
      "206. hn.nahi.btaungi\n",
      "207. sharma_ritikaa\n",
      "208. suniljyoti0001ojas\n",
      "209. garima.kamboj.31\n",
      "210. amiragill\n",
      "211. neetu.pandit.330\n",
      "212. vikaspsh\n",
      "213. kirankaur3809\n",
      "214. smriti_prasad391\n",
      "215. charlotte_waterfall\n",
      "216. grovertarun\n",
      "217. vaibhavainreallife\n",
      "218. depoetesss\n",
      "219. she_sshhivani\n",
      "220. aman03talwar\n",
      "221. garyma22\n",
      "222. bhuppsu\n",
      "223. akansha_1.7\n",
      "224. m.manisha.96\n",
      "225. j.ghsh\n",
      "226. mukh.debolina\n",
      "227. _.mahimadas._\n",
      "228. harshit_jain023\n",
      "229. im_bulbul19\n",
      "230. _madhuri_____\n",
      "231. srish_spj\n",
      "232. _shubhamjain1999\n",
      "233. varsha_maheshwari27\n",
      "234. urgoodluck07\n",
      "235. theblueeyedwondergirl\n",
      "236. covertlymaf\n",
      "237. man_preetkaur1946\n",
      "238. chhibber_muskaan\n",
      "239. aarda_s14\n",
      "240. kapil_13_sharma\n",
      "241. anshul__sehgal\n",
      "242. drlethalmaterial\n",
      "243. adnaan.fml\n",
      "244. nidhijindal300\n",
      "245. iamsaurabhkr\n",
      "246. aanchalgupta8888\n",
      "247. pulkitgoyal0934\n",
      "248. bhumisharma576\n",
      "249. jyotiarora.21\n",
      "250. thaparr_jasmine\n",
      "251. himanshipal\n",
      "252. shiksharathore\n",
      "253. ntshanu\n",
      "254. layal_manpreet\n",
      "255. sarikavij\n",
      "256. _sweta__panwar_\n",
      "257. karanposwal_20\n",
      "258. ks_photoworks\n",
      "259. s_aggarwal2\n",
      "260. the_budget.bytes\n",
      "261. rajputsushilsingh\n",
      "262. shrinkhla_sharma\n",
      "263. khanarmaan37334\n",
      "264. firdous_sheikh_78\n",
      "265. viney.sharma129\n",
      "266. rishabchittlangia\n",
      "267. swativerma.sv\n",
      "268. jasvinder5477\n",
      "269. ritikatalwar2013\n",
      "270. _tannuu18_\n",
      "271. seno_7435\n",
      "272. leenaa_ls\n",
      "273. achal.patil_205\n",
      "274. dilserekha\n",
      "275. isha_rana25\n",
      "276. sakshicourageous\n",
      "277. rajkumar_choudhary_00005\n",
      "278. aisha.singh17\n",
      "279. prakshikaushal\n",
      "280. its_sherap\n",
      "281. kalakaarsangeetacademy\n",
      "282. neeravikas\n",
      "283. i_am_queen_9358\n",
      "284. singhpreeti06\n",
      "285. factsnfiction\n",
      "286. bhanujaiswal15\n",
      "287. shivam_ahirwar__7081\n",
      "288. kalpnayadav_01\n",
      "289. rramitjain\n",
      "290. chrisj0hn\n",
      "291. loveneet.g\n",
      "292. vir_aj776\n",
      "293. tripti.rajput.3979\n",
      "294. yash_mithaiwala\n",
      "295. a.gupta1337\n",
      "296. ____shveta____\n",
      "297. meenu10133\n",
      "298. panda.ajay\n",
      "299. thebagroom___\n",
      "300. _suraj_anand_\n",
      "301. iamnot_raxhi\n",
      "302. priyanckagupta\n",
      "303. rz_rahul003\n",
      "304. hardiikk16\n",
      "305. irichasingla\n",
      "306. hyyb_bts\n",
      "307. namrata_borthakur\n",
      "308. sangamtaneja\n",
      "309. deepender.dhillon\n",
      "310. justnitika\n",
      "311. flowers_by_passion_\n",
      "312. styagi25\n",
      "313. prabh_randhawa_ps\n",
      "314. tiwariijee\n",
      "315. suj_atag\n",
      "316. manjulatlas1\n",
      "317. imaran.qureshi_\n",
      "318. just_khann41\n",
      "319. snshweta\n",
      "320. simran.k14_\n",
      "321. iee_vibha\n",
      "322. raghavmittal___\n",
      "323. tanyabadkur\n",
      "324. sharmilaparmanandka\n",
      "325. sameksha.1\n",
      "326. angelic_cutie1205\n",
      "327. actuallyaditya_\n",
      "328. _unconventional_dentist\n",
      "329. architsharma0016\n",
      "330. jinay_shah25\n",
      "331. soniapandey95\n",
      "332. _daagar_anjali\n",
      "333. nikharseth\n",
      "334. saini__0109\n",
      "335. aarushinath\n",
      "336. jenni.cathy97\n",
      "337. its.psm\n",
      "338. shwetagarg1511\n",
      "339. lawphin_pratik\n",
      "340. conquering_life_\n",
      "341. mittu4143\n",
      "342. aryansinghnegi21\n",
      "343. amans.ingh1974\n",
      "344. rahulcool65\n",
      "345. puneet.simp\n",
      "346. suryavanshi.ig\n",
      "347. priks.07\n",
      "348. nittoogopal\n",
      "349. nand_serba\n",
      "350. mukta_malik_1\n",
      "351. marwah.kanishk\n",
      "352. lavissha__kapoor\n",
      "353. preetishokeen30\n",
      "354. kunush25\n",
      "355. therajneesh1990\n",
      "356. beingankii_12\n",
      "357. kundankumarsbi\n",
      "358. sharmameenu_\n",
      "359. amishasingh05\n",
      "360. dis_ha4790\n",
      "361. shagunmiglani2622\n",
      "362. musicinasushirestraunt\n",
      "363. travelplustales\n",
      "364. oceanicabhi\n",
      "365. annisingh5804\n",
      "366. vandana.sethi.967\n",
      "367. nitimalhotra__._\n",
      "368. nainajainbaid\n",
      "369. upasanasuri\n",
      "370. aishwaryasaraswat\n",
      "371. chhavi_cj_11\n",
      "372. smriti_ses.jo\n",
      "373. divvyyaannsshhh\n",
      "374. elis_gupta\n",
      "375. iphonewala009\n",
      "376. anukruti.singh\n",
      "377. healingenergies2023\n",
      "378. rmassey1989\n",
      "379. nikkipatel545\n",
      "380. bhatt1805\n",
      "381. prashantraghav_26\n",
      "382. sidharth__here_\n",
      "383. therachitnegi\n",
      "384. aaddyyy_pvt\n",
      "385. its.shweta.2\n",
      "386. manshiiiipant\n",
      "387. sinex321\n",
      "388. finetunedwithfinesse\n",
      "389. inane_feelings\n",
      "390. priti_yummy_cakes\n",
      "391. aggarwalashika28\n",
      "392. fahad_abid_120\n",
      "393. aliatabassum__\n",
      "394. avisha.03\n",
      "395. raghav_falguni02\n",
      "396. avantikadassan14\n",
      "397. ishant_arora25\n",
      "398. _s_akshi_02\n",
      "399. diz_iz_slothkriti_\n",
      "400. saurabh_dargan\n",
      "401. kavyaaaa.gupta\n",
      "402. 113sonia\n",
      "403. surbhii_saxena\n",
      "404. kash_476\n",
      "405. shallu.gupta\n",
      "406. manasz01\n",
      "407. divyabudchauhan\n",
      "408. _paramjit_kaur\n",
      "409. anshgupta_1\n",
      "410. 1989ace\n",
      "411. parulbansal737\n",
      "412. 2456_jya\n",
      "413. bhowmick__isha\n",
      "414. kaashvitebak_729\n",
      "415. khan_swaleha_\n",
      "416. depak007dk\n",
      "417. the_dark_lord_29\n",
      "418. chitra_karmakar6\n",
      "419. misssmiley_sunshine\n",
      "420. _anushka.gaur.pvt_\n",
      "421. female_spa_centre_gurgaon\n",
      "422. naoyaluvrs\n",
      "423. anjofficial_4\n",
      "424. sourav__07\n",
      "425. sumegha_15\n",
      "426. im_disha\n",
      "427. geetakaamra\n",
      "428. _vanshika018\n",
      "429. akanksha.choudhary.21\n",
      "430. drmeenukumar\n",
      "431. ena.agarwal\n",
      "432. hiteshrao5\n",
      "433. its_sonipal\n",
      "434. _stubborn_angel20_\n",
      "435. sravanpremk\n",
      "436. mrfunnybones2022\n",
      "437. s_u_k_h76982\n",
      "438. lakshhiitaa._\n",
      "439. styling_colours\n",
      "440. pawan761987\n",
      "441. anurag.shrivastav006\n",
      "442. i.m_puneet\n",
      "443. its_prakashs\n",
      "444. ankyy_2704\n",
      "445. aman_keshari\n",
      "446. nicky_vats\n",
      "447. shibzzz_d\n",
      "448. hcr2304\n",
      "449. sharmapanks04\n",
      "450. tennyson_lap\n",
      "451. shristishah780_\n",
      "452. iishabee\n",
      "453. v1ka.5\n",
      "454. deep.axk\n",
      "455. ____saahil.____\n",
      "456. gautiii432\n",
      "457. vin1609kr\n",
      "458. aditya_keshav\n",
      "459. _oflife_and_beyond_\n",
      "460. i_vaibhav_aggarwal\n",
      "461. sudhir_nasa\n",
      "462. lordshiva_spirit\n",
      "463. payalch23\n",
      "464. shreya_nair12\n",
      "465. anshika.sinha10\n",
      "466. hegotnothing\n",
      "467. dilipgaudofficial\n",
      "468. debolinapal13\n",
      "469. dilliwaleyy\n",
      "470. aartichhillar04\n",
      "471. preeti.rit.rai\n",
      "472. jagdeep__official\n",
      "473. jitesh._.oberoi\n",
      "474. sristhijuneja\n",
      "475. ivaid31\n",
      "476. shilaaditya.roy\n",
      "477. eishasehgalgupta\n",
      "478. neha_tnwr\n",
      "479. oja_s20\n",
      "480. prathamkapoor09\n",
      "481. shubneetkaur.esskay\n",
      "482. sheeba__shns\n",
      "483. manish_kaushal85\n",
      "484. yashnag23\n",
      "485. vijayshree_soren_\n",
      "486. taranjeetkhurana\n",
      "487. delh.iballoondecorationm\n",
      "488. arora_yashica\n",
      "489. atira_farheen\n",
      "490. umme_muawiyyah\n",
      "491. makeuptroop\n",
      "492. vibhu30_\n",
      "493. aartik265\n",
      "494. monika_sharma1349\n",
      "495. kamal_adiba\n",
      "496. _iamsaurabhguha_\n",
      "497. himansh.xx\n",
      "498. prakash.ipynb\n",
      "499. trikhakash\n",
      "500. saritaarora60\n"
     ]
    }
   ],
   "source": [
    "get_followers('sodelhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba50be7",
   "metadata": {},
   "source": [
    "#### 6.2 Calling For \"FoodTalkIndia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bc7ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Account has restricted the view of all followers !!!\n",
      "But here are some of them : \n",
      "1. majhe___ale___\n",
      "2. aneelsane\n",
      "3. _r_i_s_h_a_b_11\n",
      "4. moni190497\n",
      "5. rebelroars\n",
      "6. thepaperworkshop\n",
      "7. kehihyulo\n",
      "8. _vp15_\n",
      "9. foodtravelox\n",
      "10. mai.aadi_\n",
      "11. hiya.madan\n",
      "12. ragghavhada\n",
      "13. adishree_hada\n",
      "14. archit1887\n",
      "15. lovely___girl___saina\n",
      "16. fatima_gefran\n",
      "17. ishan_i9471\n",
      "18. venivijai\n",
      "19. vasugoyall\n",
      "20. i_am_roshan_avhad\n",
      "21. gauriikukreja\n",
      "22. sristhijuneja\n",
      "23. abhi.navarora32\n",
      "24. theateamindia\n",
      "25. drunkbetch9008\n",
      "26. bliiss_blossom\n",
      "27. rajarethinam.deivendran\n",
      "28. hotelgavranbetofficial\n",
      "29. dristisanghvi\n",
      "30. hungeerrworks\n",
      "31. itzzm_ekomal\n",
      "32. mr.ompatil_official\n",
      "33. shikhalamba\n",
      "34. ramasrinivaasan\n",
      "35. mehulsaraogi\n",
      "36. adroja.meet\n",
      "37. ominious_girl\n",
      "38. anandsingh.dhingra\n",
      "39. brainsrevise\n",
      "40. miteshnimbre\n",
      "41. tejasvi.kalshain\n",
      "42. saransanjai_\n",
      "43. purnimajhaa\n",
      "44. naman_morningstar\n",
      "45. jaisinghoberoi\n",
      "46. chughkevin\n",
      "47. kunalkhattar\n",
      "48. king_akky1008\n",
      "49. aayu__13__07\n",
      "50. ukey1478\n"
     ]
    }
   ],
   "source": [
    "get_followers('foodtalkindia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e24d65",
   "metadata": {},
   "source": [
    "#### 6.3 Common Followers of \"foodtalkindia\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabfbe5",
   "metadata": {},
   "source": [
    "#### Opening \"Foodtalkindia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6668765",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_and_open_a_profile('foodtalkindia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12b991c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Followed_by_button = driver.find_element(By.PARTIAL_LINK_TEXT, 'Followed by')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79c51635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Followed_by_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff00e8",
   "metadata": {},
   "source": [
    "#### Printing out the common followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcd4f582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aayu__13__07\n"
     ]
    }
   ],
   "source": [
    "followed_by = driver.find_element(By.XPATH, \"//span[starts-with(@class, 'x1lliihq x193iq5w x6ikm8r x10wlt62 xlyipyv xuxw1ft')]//div[@class = 'xt0psk2']//a\")\n",
    "html_obj = BeautifulSoup(followed_by.get_attribute('innerHTML'), 'html.parser')\n",
    "follower = html_obj.string\n",
    "print(follower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6dfd4",
   "metadata": {},
   "source": [
    "#### Note : \n",
    "**There is Just one common connection But, There are no such followers from my account whom I follow and they do not follow me back**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412e885",
   "metadata": {},
   "source": [
    "### Problem 7: Check the story of ‘coding.ninjas’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77157f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status_of_story(profile_name) :\n",
    "    try :\n",
    "        search_and_open_a_profile(profile_name)\n",
    "    except :\n",
    "        print(\"Couldn't Open the Profile\")\n",
    "        \n",
    "    ### by analyzing the html content it was found that for\n",
    "    ### not seen -> height = 114 and disabled = false\n",
    "    ### seen->height = 109 disabled = false\n",
    "    ### not uploaded -> height = 114 and disabled = true\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    div_tag_to_check_disable = wait.until(EC.presence_of_element_located((By.XPATH, '//div[starts-with(@class, \"x78zum5 xdt5ytf x2lah0s xl56j7k x1n2onr6 xbn8dsz x184cenk x16fuon9 x5bv2cf x9ozhqo\")]/div')))\n",
    "    disability = div_tag_to_check_disable.get_attribute('aria-disabled')\n",
    "    canvas_tag = driver.find_element(By.TAG_NAME,'canvas')\n",
    "    height = canvas_tag.get_attribute('height')\n",
    "    \n",
    "    if disability == 'true' :\n",
    "        print('There is no story !!!')\n",
    "    else :\n",
    "        if height == '109' :\n",
    "            print('story is already seen !!!')\n",
    "        else :\n",
    "            print('There is a new story which has not been seen yet !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633161ff",
   "metadata": {},
   "source": [
    "#### 7.1 Checking Function on a new story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5158d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a new story which has not been seen yet !!!\n"
     ]
    }
   ],
   "source": [
    "check_status_of_story('coding.ninjas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c861b41",
   "metadata": {},
   "source": [
    "#### 7.2 Checking Function after viewing the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b39f1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story is already seen !!!\n"
     ]
    }
   ],
   "source": [
    "check_status_of_story('coding.ninjas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa09a2",
   "metadata": {},
   "source": [
    "### SUBMITTED BY - PRATEEK SARNA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
